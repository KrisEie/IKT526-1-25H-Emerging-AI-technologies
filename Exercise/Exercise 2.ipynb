{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09714ab3-e907-4dfd-aab3-3799631ccd5e",
   "metadata": {},
   "source": [
    "# Lab 2: Diffusion Models Implementation\n",
    "**Duration:** 3 hours  \n",
    "**Objectives:**\n",
    "- Implement and understand VAEs as foundation for diffusion\n",
    "- Build simple diffusion process from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52f439f-d251-4dd9-bc67-5bb52dc31796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make necessary imports\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import MNIST dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# TODO: Ensure reproducibility\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bb2bda-84ea-458f-aa33-3ff296e41270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect GPU, use CPU if not\n",
    "def setup_device():\n",
    "    \"\"\"\n",
    "    Automatically detect and setup the best available device(s)\n",
    "    Returns device and whether multiple GPUs are available\n",
    "    \"\"\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        device = torch.device('cuda:0')\n",
    "        \n",
    "        print(f\"GPU acceleration enabled!\")\n",
    "        print(f\"   Available GPUs: {num_gpus}\")\n",
    "\n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "            print(f\"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)\") \n",
    "\n",
    "        multi_gpu = num_gpus > 1\n",
    "        if multi_gpu:\n",
    "            print(f\"Multi-GPU training will be used ({num_gpus} GPUs)\")\n",
    "        return device, multi_gpu\n",
    "    else:\n",
    "        print(\"No GPU detected, using CPU\")\n",
    "        return torch.device('cpu'), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89985ca-a65a-480d-be7d-90b844695339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up compute device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d487e-31cb-44a0-bcd6-838bfc9b3d28",
   "metadata": {},
   "source": [
    "### Exercise 1: Variational Autoencoder on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d60831-64c6-4506-a40e-402b99760ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load MNIST dataset and create dataloaders\n",
    "\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2b620-c533-4418-a3fa-e92980e1f3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=[400,200], latent_dim=2):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim[0])\n",
    "        self.fc2 = nn.Linear(hidden_dim[0], hidden_dim[1])\n",
    "        self.fc_mu = nn.Linear(hidden_dim[1], latent_dim)\n",
    "        self.fc_logvar = nn.Linear(hidden_dim[1], latent_dim)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.fc4 = nn.Linear(latent_dim, hidden_dim[1])\n",
    "        self.fc5 = nn.Linear(hidden_dim[1], hidden_dim[0])\n",
    "        self.fc6 = nn.Linear(hidden_dim[0], input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        \"\"\"Encode input to latent distribution parameters\"\"\"\n",
    "        \n",
    "        #TODO: Implement encoder\n",
    "        # 1. Pass x through fc1 with ReLU activation\n",
    "        # 2. Compute mu using fc_mu\n",
    "        # 3. Compute log_var using fc_logvar\n",
    "        # 4. Return mu and log_var\n",
    "        \n",
    "        return pass\n",
    "    \n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        \n",
    "        #TODO: Implement reparameterization\n",
    "        # z = mu + eps * std, where eps ~ N(0,1)\n",
    "        \n",
    "        return pass\n",
    "    \n",
    "    def decode(self, z):\n",
    "        \"\"\"Decode latent representation back to data space\"\"\"\n",
    "        \n",
    "        #TODO: Implement decoder\n",
    "        # 1. Pass z through fc3 with ReLU activation\n",
    "        # 2. Pass through fc4 with sigmoid activation\n",
    "        # 3. Return reconstructed output\n",
    "        \n",
    "        return pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        reconstruction = self.decode(z)\n",
    "        return reconstruction, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6db0b6-6b93-4dd5-ba3c-1b54c3848643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(reconstruction, original, mu, log_var):\n",
    "    \"\"\"\n",
    "    VAE loss = Reconstruction loss + KL divergence\n",
    "    \"\"\"\n",
    "    #TODO: Implement VAE loss\n",
    "    # 1. Calculate BCE reconstruction loss (Because of MNIST dataset nature, MSE if continuous space)\n",
    "    # 2. Calculate KL divergence: -0.5 * sum(1 + log_var - mu^2 - exp(log_var))\n",
    "    # 3. Return total loss\n",
    "    \n",
    "    # Implement Reconstruction loss (Binary Cross Entropy)\n",
    "    \n",
    "    # Implement KL divergence\n",
    "    \n",
    "    return pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc389111-4567-44df-ae11-764cd629105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, train_loader, epochs=10, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    \n",
    "    train_losses = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        for batch_idx, (data, _) in enumerate(train_loader):\n",
    "            data = data.view(-1, 784).to(device)\n",
    "            \n",
    "            #TODO: Implement training step\n",
    "            # 1. Zero gradients\n",
    "            # 2. Forward pass\n",
    "            # 3. Calculate loss\n",
    "            # 4. Backward pass\n",
    "            # 5. Update weights\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "        avg_loss = epoch_loss / len(train_loader.dataset)\n",
    "        train_losses.append(avg_loss)\n",
    "        print(f'Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "    \n",
    "    return train_losses\n",
    "\n",
    "# Initialize and train VAE\n",
    "vae_model = VAE(latent_dim=2).to(device)  # 2D latent for visualization\n",
    "if multi_gpu:\n",
    "    vae_model = nn.DataParallel(vae_model)\n",
    "losses = train_vae(vae_model, train_loader, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186546eb-e2d9-4b0f-b75b-a5fe5350ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the 2D latent space\n",
    "def visualize_latent_space(model, test_loader):\n",
    "    model.eval()\n",
    "    latents = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.view(-1, 784).to(device)\n",
    "            if multi_gpu:\n",
    "                mu, _ = model.module.encode(data)\n",
    "            else:\n",
    "                mu, _ = model.encode(data)\n",
    "            latents.append(mu.cpu().numpy())\n",
    "            labels.append(label.numpy())\n",
    "    \n",
    "    latents = np.concatenate(latents)\n",
    "    labels = np.concatenate(labels)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    scatter = plt.scatter(latents[:, 0], latents[:, 1], c=labels, cmap='tab10')\n",
    "    plt.colorbar(scatter)\n",
    "    plt.xlabel('Latent Dimension 1')\n",
    "    plt.ylabel('Latent Dimension 2')\n",
    "    plt.title('VAE Latent Space Visualization')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_latent_space(vae_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc221f9-3a98-4162-a19c-127de7c19814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize latent interpolation between two digits\n",
    "def interpolate_latent(model, start_digit=0, end_digit=9, n_steps=10):\n",
    "    \"\"\"Interpolate between two digits in latent space\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Get examples of start and end digits\n",
    "    for data, labels in test_loader:\n",
    "        start_idx = (labels == start_digit).nonzero()[0]\n",
    "        end_idx = (labels == end_digit).nonzero()[0]\n",
    "        break\n",
    "    \n",
    "    start_img = data[start_idx].view(-1, 784).to(device)\n",
    "    end_img = data[end_idx].view(-1, 784).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Encode to latent space\n",
    "        if multi_gpu:\n",
    "                start_mu, _ = model.module.encode(start_img)\n",
    "                end_mu, _ = model.module.encode(end_img)\n",
    "        else:\n",
    "            start_mu, _ = model.encode(start_img)\n",
    "            end_mu, _ = model.encode(end_img)\n",
    "        \n",
    "        # Interpolate\n",
    "        fig, axes = plt.subplots(1, n_steps, figsize=(15, 2))\n",
    "        for i, alpha in enumerate(np.linspace(0, 1, n_steps)):\n",
    "            z = (1-alpha) * start_mu + alpha * end_mu\n",
    "            if multi_gpu:\n",
    "                reconstruction = model.module.decode(z)\n",
    "            else:\n",
    "                reconstruction = model.decode(z)\n",
    "            \n",
    "            axes[i].imshow(reconstruction.cpu().view(28, 28), cmap='gray')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle(f'Interpolation from {start_digit} to {end_digit}')\n",
    "        plt.show()\n",
    "\n",
    "interpolate_latent(vae_model, 0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ccc9c2-087b-4d9b-85a4-644524342fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize latent interpolation\n",
    "\n",
    "def plot_latent_space(model, scale=1.0, n=25, digit_size=28, figsize=15):\n",
    "    # display a n*n 2D manifold of digits\n",
    "    figure = np.zeros((digit_size * n, digit_size * n))\n",
    "\n",
    "    # construct a grid \n",
    "    grid_x = np.linspace(-scale, scale, n)\n",
    "    grid_y = np.linspace(-scale, scale, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to(device)\n",
    "            if multi_gpu:\n",
    "                x_decoded = model.module.decode(z_sample)\n",
    "            else:\n",
    "                x_decoded = model.decode(z_sample)\n",
    "            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n",
    "            figure[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size,] = digit\n",
    "\n",
    "    plt.figure(figsize=(figsize, figsize))\n",
    "    plt.title('VAE Latent Space Visualization')\n",
    "    start_range = digit_size // 2\n",
    "    end_range = n * digit_size + start_range\n",
    "    pixel_range = np.arange(start_range, end_range, digit_size)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range, sample_range_x)\n",
    "    plt.yticks(pixel_range, sample_range_y)\n",
    "    plt.xlabel(\"mean, z [0]\")\n",
    "    plt.ylabel(\"var, z [1]\")\n",
    "    plt.imshow(figure, cmap=\"Greys_r\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_latent_space(vae_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32ff239-e9bd-492a-8c8f-a4953191c8e1",
   "metadata": {},
   "source": [
    "### Exercise 2: Building Diffusion from Scratch\n",
    "\n",
    "Now we'll implement a simple diffusion process on 1D data to understand the core concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ec4543-dc67-4f34-b8ab-24ee66561cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spiral_data(n_samples=1000):\n",
    "    \"\"\"Generate 2D spiral data for diffusion\"\"\"\n",
    "    theta = np.sqrt(np.random.rand(n_samples)) * 4 * np.pi\n",
    "    r = theta + np.random.randn(n_samples) * 0.1\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "    return np.stack([x, y], axis=1).astype(np.float32)\n",
    "\n",
    "# Generate and visualize data\n",
    "data = generate_spiral_data(2000)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(data[:, 0], data[:, 1], alpha=0.5, s=1)\n",
    "plt.title('Original Spiral Data')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d981122-60c8-43b0-ba97-2824c4782193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForwardDiffusion:\n",
    "    def __init__(self, num_timesteps=1000, beta_start=1e-4, beta_end=0.02):\n",
    "        self.num_timesteps = num_timesteps\n",
    "        \n",
    "        # Linear schedule for beta\n",
    "        self.betas = torch.linspace(beta_start, beta_end, num_timesteps).to(device)\n",
    "        self.alphas = 1 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(self.alphas, dim=0)\n",
    "        \n",
    "        # Pre-compute values for sampling\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - self.alphas_cumprod)\n",
    "    \n",
    "    def add_noise(self, x_0, t):\n",
    "        \"\"\"Add noise to x_0 according to timestep t\"\"\"\n",
    "        \n",
    "        #TODO: Implement forward diffusion\n",
    "        # x_t = sqrt(alpha_cumprod_t) * x_0 + sqrt(1 - alpha_cumprod_t) * eps\n",
    "        # where eps ~ N(0, 1)\n",
    "        \n",
    "        return x_t, noise\n",
    "\n",
    "# Visualize forward process\n",
    "forward_diff = ForwardDiffusion(num_timesteps=1000)\n",
    "x_0 = torch.tensor(data[:500]).to(device)\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
    "timesteps = [0, 100, 250, 500, 999]\n",
    "\n",
    "for idx, t in enumerate(timesteps):\n",
    "    t_tensor = torch.full((500,), t, dtype=torch.long)\n",
    "    x_t, _ = forward_diff.add_noise(x_0, t_tensor)\n",
    "    x_t_plot = x_t.cpu()\n",
    "    axes[idx].scatter(x_t_plot[:, 0], x_t_plot[:, 1], alpha=0.5, s=1)\n",
    "    axes[idx].set_title(f't = {t}')\n",
    "    axes[idx].axis('equal')\n",
    "    axes[idx].set_xlim(-15, 15)\n",
    "    axes[idx].set_ylim(-15, 15)\n",
    "\n",
    "plt.suptitle('Forward Diffusion Process')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f8460-e768-4e91-be20-107c36964803",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleDenoiser(nn.Module):\n",
    "    def __init__(self, data_dim=2, hidden_dim=128, time_dim=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Time embedding\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, time_dim),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        \n",
    "        # Main network\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(data_dim + time_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, data_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        \"\"\"Predict noise given noisy data x and timestep t\"\"\"\n",
    "        \n",
    "        #TODO: Implement forward pass\n",
    "        # 1. Embed timestep using self.time_embed\n",
    "        # 2. Concatenate with x\n",
    "        # 3. Pass through network\n",
    "        \n",
    "        return predicted_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bc2e3b-938e-4e4b-8a54-b9be5455bcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion(model, data, forward_diffusion, epochs=1000, batch_size=128, lr=1e-3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "    \n",
    "    losses = []\n",
    "    data_tensor = torch.tensor(data)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Sample batch\n",
    "        idx = torch.randint(0, len(data), (batch_size,))\n",
    "        batch = data_tensor[idx].to(device)\n",
    "        \n",
    "        # Sample random timesteps\n",
    "        t = torch.randint(0, forward_diffusion.num_timesteps, (batch_size,)).to(device)\n",
    "        \n",
    "        #TODO: Implement training step\n",
    "        # 1. Add noise to batch using forward diffusion\n",
    "        # 2. Predict noise using model\n",
    "        # 3. Calculate MSE loss between true and predicted noise\n",
    "        # 4. Backpropagate and update\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item():.6f}')\n",
    "    \n",
    "    return losses\n",
    "\n",
    "# Train the model\n",
    "denoiser = SimpleDenoiser().to(device)\n",
    "if multi_gpu:\n",
    "    denoiser = nn.DataParallel(denoiser)\n",
    "\n",
    "\n",
    "losses = train_diffusion(denoiser, data, forward_diff, epochs=5000, batch_size=256)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(losses)\n",
    "plt.title('Diffusion Training Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63933a77-6b03-4929-be37-10c1ab3b39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample_diffusion(model, forward_diffusion, n_samples=500):\n",
    "    \"\"\"Generate samples using reverse diffusion\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Start from pure noise\n",
    "    x = torch.randn(n_samples, 2).to(device)\n",
    "    \n",
    "    # Store intermediate steps\n",
    "    trajectory = [x.cpu().numpy()]\n",
    "    \n",
    "    # Reverse diffusion\n",
    "    for t in reversed(range(forward_diffusion.num_timesteps)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device)\n",
    "        \n",
    "        #TODO: Implement reverse diffusion step\n",
    "        # The reverse process approximates the posterior p(x_{t-1} | x_t) ≈ N(x_{t-1}; μ_θ(x_t, t), σ_t^2 I),\n",
    "        # where μ_θ is the predicted mean derived from the model's noise prediction ε_θ(x_t, t),\n",
    "        # and σ_t is the posterior variance.\n",
    "        \n",
    "        # 1. Predict noise using model:\n",
    "        # The model ε_θ(x_t, t) estimates the noise ε that was added in the forward process.\n",
    "        # This is trained to minimize the difference between predicted and actual noise.\n",
    "\n",
    "        # 2. Compute parameters for the reverse step:\n",
    "        # Gather α_t = 1 - β_t and ᾱ_t = ∏_{i=1}^t α_i\n",
    "        # Compute posterior standard deviation σ_t:\n",
    "        # For t > 0, σ_t = √[(1 - ᾱ_{t-1}) / (1 - ᾱ_t) * β_t],\n",
    "        # which is the scaled variance from the DDPM posterior (often denoted as ~β_t).\n",
    "        # At t=0, no additional noise is added (deterministic final step).\n",
    "        \n",
    "        # 2. Remove predicted noise (simplified DDPM equation)\n",
    "        # Note: This is simplified - real DDPM has more complex sampling\n",
    "\n",
    "        # 3. Compute the denoised mean μ_θ(x_t, t):\n",
    "        # μ_θ = (1 / √α_t) * (x_t - ((1 - α_t) / √(1 - ᾱ_t)) * ε_θ(x_t, t))\n",
    "        # This removes the predicted noise scaled by the forward process coefficients.\n",
    "\n",
    "        # 4. Add posterior noise for sampling:\n",
    "        # x_{t-1} = μ_θ + σ_t * z\n",
    "        # This introduces the appropriate variance to match the reverse transition.\n",
    "\n",
    "        # Note: This implements the standard DDPM sampling equation.\n",
    "        # For deterministic sampling (e.g., DDIM), the noise term can be omitted or modified.\n",
    "        # Variations may include different variance schedules or guidance.\n",
    "        \n",
    "        if t % 20 == 0:\n",
    "            trajectory.append(x.cpu().numpy())\n",
    "    \n",
    "    return x.cpu().numpy(), trajectory\n",
    "\n",
    "# Generate samples\n",
    "samples, trajectory = sample_diffusion(denoiser, forward_diff)\n",
    "\n",
    "# Visualize results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "axes[0].scatter(data[:, 0], data[:, 1], alpha=0.5, s=1)\n",
    "axes[0].set_title('Original Data')\n",
    "axes[0].axis('equal')\n",
    "\n",
    "axes[1].scatter(samples[:, 0], samples[:, 1], alpha=0.5, s=1)\n",
    "axes[1].set_title('Generated Samples')\n",
    "axes[1].axis('equal')\n",
    "\n",
    "# Show trajectory\n",
    "axes[2].set_title('Reverse Diffusion Process')\n",
    "for i, step in enumerate(trajectory[::2]):\n",
    "    alpha = i / len(trajectory[::2])\n",
    "    axes[2].scatter(step[:100, 0], step[:100, 1], alpha=alpha, s=1, c=[[alpha, 0, 1-alpha]])\n",
    "axes[2].axis('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
