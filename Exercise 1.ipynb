{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "357e4ee9-1f99-41ab-8196-e683abc58b52",
   "metadata": {},
   "source": [
    "# Exercise 1: Introduction to GenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f50d3e-ec27-4991-a6b1-b4b0a3276b05",
   "metadata": {},
   "source": [
    "## Part 1: PyTorch Refresher - Building a 2D Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3041d119-cf32-4615-9b71-71b37f0a99f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make necessary imports\n",
    "\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# TASK: Ensure reproducibility\n",
    "\n",
    "\n",
    "# TODO: Check for GPU acceleration and use if available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c9eb5-7970-4009-9989-cb59d58417e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2D classification dataset\n",
    "def generate_classification_data(n_samples=1000, n_classes=4, device=device):\n",
    "    \"\"\"Generate 2D classification datasets\"\"\"\n",
    "    \n",
    "    # Multi-class spiral\n",
    "    \n",
    "    points_per_class = n_samples // n_classes\n",
    "    X, labels = [], []\n",
    "\n",
    "    \n",
    "    \n",
    "    for class_id in range(n_classes):\n",
    "        # Create spiral arms with different starting angles\n",
    "        t = np.linspace(0.1, 4*np.pi, points_per_class)\n",
    "        radius = t\n",
    "        angle = t + (class_id * 2*np.pi / n_classes)\n",
    "        \n",
    "        x_coords = radius * np.cos(angle) + np.random.normal(0, 0.3, points_per_class)\n",
    "        y_coords = radius * np.sin(angle) + np.random.normal(0, 0.3, points_per_class)\n",
    "        \n",
    "        X.append(np.column_stack([x_coords, y_coords]))\n",
    "        labels.append(np.full(points_per_class, class_id))\n",
    "        \n",
    "    X = np.vstack(X)\n",
    "    y = np.concatenate(labels)\n",
    "        \n",
    "    # Normalize to reasonable range\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    \n",
    "    return torch.FloatTensor(X).to(device), torch.LongTensor(y).to(device)\n",
    "\n",
    "\n",
    "# TODO: Generate and Visualize the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b644b4-1062-460e-b107-78190a16cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=[64, 32], output_dim=2):\n",
    "        super(SimpleClassifier, self).__init__()\n",
    "        \n",
    "        # TODO: Define your network layers here\n",
    "        # Replace with your implementation\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # TODO: Implement forward pass\n",
    "        return  # Your implementation here\n",
    "\n",
    "# TODO: Initialize the model, loss, and optimizer\n",
    "model = \n",
    "print(model)\n",
    "criterion = # Multi-class classification loss\n",
    "optimizer = \n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8252e5ab-3b78-45c2-9e41-5e07f147c158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create data splits (train/test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf87751-3ade-4d45-aaf5-33791e0540f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, X_train, y_train, epochs=100):\n",
    "    model.train()\n",
    "    losses, accuracies = [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #TODO: Implement model training\n",
    "\n",
    "        # Accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        accuracy = (predicted == y_train).float().mean().item()\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}, Accuracy: {accuracy:.3f}')\n",
    "    \n",
    "    return losses, accuracies\n",
    "\n",
    "\n",
    "# Train the model\n",
    "losses, accuracies = train_model(model, X_train, y_train, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adef86af-0876-486e-8fb3-cb1a086b83e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate model\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbda08db-305f-48a2-b0f0-e9253152c089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot training curves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74962eb3-90ca-47b2-8d0b-76d771cf2484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Optional Decision Boundary Visualization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f86d59-458f-4e55-b098-203029d044c0",
   "metadata": {},
   "source": [
    "## Part 2: From Classification to Generation (Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65a8db-fad6-482f-8195-4f4c05440b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_device():\n",
    "    \"\"\"\n",
    "    Automatically detect and setup the best available device(s)\n",
    "    Returns device and whether multiple GPUs are available\n",
    "    \"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        num_gpus = torch.cuda.device_count()\n",
    "        device = torch.device('cuda:0')\n",
    "        \n",
    "        print(f\"GPU acceleration enabled!\")\n",
    "        print(f\"   Available GPUs: {num_gpus}\")\n",
    "        for i in range(num_gpus):\n",
    "            gpu_name = torch.cuda.get_device_name(i)\n",
    "            gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
    "            print(f\"   GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "        \n",
    "        multi_gpu = num_gpus > 1\n",
    "        if multi_gpu:\n",
    "            print(f\"Multi-GPU training will be used ({num_gpus} GPUs)\")\n",
    "        \n",
    "        return device, multi_gpu\n",
    "    else:\n",
    "        print(\"No GPU detected, using CPU\")\n",
    "        print(\"   Note: Training will be slower but still functional\")\n",
    "        return torch.device('cpu'), False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd46ec7-f55d-4f90-82fe-4edd9376bb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"\"\" Generator Network \"\"\"\n",
    "    \n",
    "    def __init__(self, noise_dim=10, hidden_dim=128):\n",
    "        super(Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(noise_dim, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 2),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Better weight initialization\n",
    "        self.apply(self._weights_init)\n",
    "    \n",
    "    def _weights_init(self, m):\n",
    "        \"\"\"Custom weight initialization for better training stability\"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, noise):\n",
    "        return self.net(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a3c567-6f1d-4b09-9457-d97976f71f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    \"\"\"Discriminator Network\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, 64),\n",
    "            nn.LeakyReLU(0.2, True),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Better weight initialization\n",
    "        self.apply(self._weights_init)\n",
    "    \n",
    "    def _weights_init(self, m):\n",
    "        \"\"\"Custom weight initialization for better training stability\"\"\"\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4709590a-9ee6-4182-b57b-b7933f3f8307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_real_data(n_samples=5000, dataset_type='figure8', device='cpu'):\n",
    "    \"\"\"Generate different types of 2D datasets\"\"\"\n",
    "    \n",
    "    if dataset_type == 'circles':\n",
    "        data, _ = make_circles(n_samples=n_samples, noise=0.05, factor=0.4)\n",
    "        \n",
    "    elif dataset_type == 'moons':\n",
    "        data, _ = make_moons(n_samples=n_samples, noise=0.05)\n",
    "        \n",
    "    elif dataset_type == 'blobs':\n",
    "        data, _ = make_blobs(n_samples=n_samples, centers=3, cluster_std=0.4)\n",
    "        \n",
    "    elif dataset_type == 'spiral':\n",
    "        t = np.linspace(0, 3*np.pi, n_samples)\n",
    "        r = t / (3*np.pi) * 2\n",
    "        x = r * np.cos(t) + np.random.normal(0, 0.05, n_samples)\n",
    "        y = r * np.sin(t) + np.random.normal(0, 0.05, n_samples)\n",
    "        data = np.column_stack([x, y])\n",
    "        \n",
    "    elif dataset_type == 'figure8':\n",
    "        # Better figure-8 pattern\n",
    "        t = np.linspace(0, 2*np.pi, n_samples)\n",
    "        scale = 0.8\n",
    "        x = scale * np.sin(t) + np.random.normal(0, 0.03, n_samples)\n",
    "        y = scale * np.sin(2*t) / 2 + np.random.normal(0, 0.03, n_samples)\n",
    "        data = np.column_stack([x, y])\n",
    "        \n",
    "    elif dataset_type == 'heart':\n",
    "        # Heart shape for fun!\n",
    "        t = np.linspace(0, 2*np.pi, n_samples)\n",
    "        x = 16 * np.sin(t)**3\n",
    "        y = 13 * np.cos(t) - 5 * np.cos(2*t) - 2 * np.cos(3*t) - np.cos(4*t)\n",
    "        x = x / 20 + np.random.normal(0, 0.03, n_samples)\n",
    "        y = y / 20 + np.random.normal(0, 0.03, n_samples)\n",
    "        data = np.column_stack([x, y])\n",
    "    \n",
    "    # Better normalization to [-0.8, 0.8] to avoid saturation\n",
    "    data_min, data_max = data.min(axis=0), data.max(axis=0)\n",
    "    data = 1.6 * (data - data_min) / (data_max - data_min) - 0.8\n",
    "    \n",
    "    return torch.FloatTensor(data).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c089a778-cb9d-448b-93fb-ecbc58d3cdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_comparison(real_data, fake_data, title_prefix=\"\", real_label=\"Real\", \n",
    "                        fake_label=\"Generated\", fake_color='red', figsize=(15, 4)):\n",
    "    \"\"\"Plotting function\"\"\"\n",
    "    \n",
    "    # Move data to CPU for plotting\n",
    "    if torch.is_tensor(real_data):\n",
    "        real_np = real_data.cpu().numpy()\n",
    "    else:\n",
    "        real_np = real_data\n",
    "        \n",
    "    if torch.is_tensor(fake_data):\n",
    "        fake_np = fake_data.cpu().numpy()\n",
    "    else:\n",
    "        fake_np = fake_data\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=figsize)\n",
    "    \n",
    "    # Real data\n",
    "    axes[0].scatter(real_np[:, 0], real_np[:, 1], alpha=0.7, c='blue', s=12, edgecolors='none')\n",
    "    axes[0].set_title(f'{real_label}', fontweight='bold', fontsize=14)\n",
    "    axes[0].set_xlim(-1.2, 1.2)\n",
    "    axes[0].set_ylim(-1.2, 1.2)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    axes[0].set_aspect('equal')\n",
    "    \n",
    "    # Generated data\n",
    "    axes[1].scatter(fake_np[:, 0], fake_np[:, 1], alpha=0.7, c=fake_color, s=12, edgecolors='none')\n",
    "    axes[1].set_title(f'{fake_label}', fontweight='bold', fontsize=14)\n",
    "    axes[1].set_xlim(-1.2, 1.2)\n",
    "    axes[1].set_ylim(-1.2, 1.2)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    axes[1].set_aspect('equal')\n",
    "    \n",
    "    # Overlay comparison\n",
    "    axes[2].scatter(real_np[:, 0], real_np[:, 1], alpha=0.6, c='blue', s=10, label=real_label, edgecolors='none')\n",
    "    axes[2].scatter(fake_np[:, 0], fake_np[:, 1], alpha=0.6, c=fake_color, s=10, label=fake_label, edgecolors='none')\n",
    "    axes[2].set_title('Overlay Comparison', fontweight='bold', fontsize=14)\n",
    "    axes[2].set_xlim(-1.2, 1.2)\n",
    "    axes[2].set_ylim(-1.2, 1.2)\n",
    "    axes[2].grid(True, alpha=0.3)\n",
    "    axes[2].legend()\n",
    "    axes[2].set_aspect('equal')\n",
    "    \n",
    "    if title_prefix:\n",
    "        fig.suptitle(f'{title_prefix}', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fdfea9-4fe3-4bf2-8105-726a46abf48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, real_data, device, multi_gpu=False,\n",
    "                     noise_dim=10, epochs=3000, batch_size=256, lr_g=0.0002, lr_d=0.0001):\n",
    "    \"\"\"GAN training\"\"\"\n",
    "    \n",
    "    # Setup for multiple GPUs\n",
    "    if multi_gpu:\n",
    "        generator = nn.DataParallel(generator)\n",
    "        discriminator = nn.DataParallel(discriminator)\n",
    "        print(\"Using DataParallel for multi-GPU training\")\n",
    "    \n",
    "    # Move models to device\n",
    "    generator = generator.to(device)\n",
    "    discriminator = discriminator.to(device)\n",
    "    \n",
    "    # Different learning rates for better stability\n",
    "    # criterion = nn.BCELoss()\n",
    "    criterion = nn.MSELoss()  # Instead of BCELoss\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=lr_g, betas=(0.5, 0.999))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=lr_d, betas=(0.5, 0.999))\n",
    "    \n",
    "    # Track losses\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print(f\"Starting stable GAN training...\")\n",
    "    print(f\"Generator LR: {lr_g}, Discriminator LR: {lr_d}\")\n",
    "    print(f\"Batch size: {batch_size}, Epochs: {epochs}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Label smoothing for better training\n",
    "    real_label = 0.9  # Instead of 1.0\n",
    "    fake_label = 0.0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Create batches\n",
    "        n_batches = len(real_data) // batch_size\n",
    "        \n",
    "        for batch_idx in range(n_batches):\n",
    "            # Get batch\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            real_batch = real_data[start_idx:end_idx]\n",
    "            current_batch_size = len(real_batch)\n",
    "            \n",
    "            # =====================\n",
    "            # Train Discriminator (more often than generator)\n",
    "            # =====================\n",
    "            for _ in range(2):  # Train discriminator twice per generator update\n",
    "                optimizer_d.zero_grad()\n",
    "                \n",
    "                # Real data\n",
    "                real_pred = discriminator(real_batch)\n",
    "                real_labels = torch.full((current_batch_size,), real_label, device=device)\n",
    "                real_loss = criterion(real_pred, real_labels)\n",
    "                \n",
    "                # Fake data\n",
    "                noise = torch.randn(current_batch_size, noise_dim, device=device)\n",
    "                fake_batch = generator(noise).detach()\n",
    "                fake_pred = discriminator(fake_batch)\n",
    "                fake_labels = torch.full((current_batch_size,), fake_label, device=device)\n",
    "                fake_loss = criterion(fake_pred, fake_labels)\n",
    "                \n",
    "                # Update discriminator\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                d_loss.backward()\n",
    "                optimizer_d.step()\n",
    "            \n",
    "            # ==================\n",
    "            # Train Generator\n",
    "            # ==================\n",
    "            optimizer_g.zero_grad()\n",
    "            \n",
    "            noise = torch.randn(current_batch_size, noise_dim, device=device)\n",
    "            fake_batch = generator(noise)\n",
    "            fake_pred = discriminator(fake_batch)\n",
    "            \n",
    "            # Generator wants discriminator to think fake is real\n",
    "            g_labels = torch.full((current_batch_size,), real_label, device=device)\n",
    "            g_loss = criterion(fake_pred, g_labels)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "        \n",
    "        # Track losses\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "        \n",
    "        # Print progress\n",
    "        if epoch % 500 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            print(f\"Epoch {epoch:4d} | D_loss: {d_loss.item():.4f} | G_loss: {g_loss.item():.4f} | Time: {elapsed:.1f}s\")\n",
    "            \n",
    "            # Show intermediate results\n",
    "            if epoch > 0:\n",
    "                # clear_output(wait=True)\n",
    "                with torch.no_grad():\n",
    "                    noise = torch.randn(500, noise_dim, device=device)\n",
    "                    fake_samples = generator(noise)\n",
    "                plot_data_comparison(\n",
    "                    real_data, fake_samples,\n",
    "                    title_prefix=f\"Training Progress - Epoch {epoch}\",\n",
    "                    fake_color='orange'\n",
    "                )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\nTraining completed in {total_time:.1f} seconds!\")\n",
    "    \n",
    "    return g_losses, d_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9947587-300c-428a-be73-97a0934daff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_losses(g_losses, d_losses, device_name=\"\"):\n",
    "    \"\"\"Enhanced loss plotting\"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(g_losses, label='Generator Loss', alpha=0.8, color='orange', linewidth=2)\n",
    "    plt.plot(d_losses, label='Discriminator Loss', alpha=0.8, color='blue', linewidth=2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title(f'GAN Training Losses {device_name}')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Moving average for smoother visualization\n",
    "    plt.subplot(1, 3, 2)\n",
    "    window = max(10, len(g_losses) // 20)\n",
    "    if window > 1:\n",
    "        g_smooth = np.convolve(g_losses, np.ones(window)/window, mode='valid')\n",
    "        d_smooth = np.convolve(d_losses, np.ones(window)/window, mode='valid')\n",
    "        plt.plot(g_smooth, label='Generator (Smoothed)', color='orange', linewidth=2)\n",
    "        plt.plot(d_smooth, label='Discriminator (Smoothed)', color='blue', linewidth=2)\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss (Moving Average)')\n",
    "        plt.title('Smoothed Training Curves')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Loss ratio for balance assessment\n",
    "    plt.subplot(1, 3, 3)\n",
    "    if len(g_losses) > 10:\n",
    "        ratio = np.array(g_losses[10:]) / (np.array(d_losses[10:]) + 1e-8)\n",
    "        plt.plot(ratio, color='green', linewidth=2)\n",
    "        plt.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='Perfect Balance')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Generator/Discriminator Loss Ratio')\n",
    "        plt.title('Training Balance')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92825632-93bf-4605-9c78-87d4dfffea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(generator, noise_dim, n_samples, device):\n",
    "    \"\"\"Generate samples efficiently\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(n_samples, noise_dim, device=device)\n",
    "        samples = generator(noise)\n",
    "    generator.train()\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58531245-4f8a-489a-aa1e-78fb4de9cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NOISE_DIM = 10  # Higher dimensional noise for better diversity\n",
    "EPOCHS = 2000\n",
    "DATASET_TYPE = 'heart'  # Options: 'circles', 'moons', 'blobs', 'spiral', 'figure8', 'heart'\n",
    "BATCH_SIZE = 256\n",
    "N_SAMPLES = 2048\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- Dataset: {DATASET_TYPE}\")\n",
    "print(f\"- Noise dimensions: {NOISE_DIM}\")\n",
    "print(f\"- Training epochs: {EPOCHS}\")\n",
    "print(f\"- Batch size: {BATCH_SIZE}\")\n",
    "print(f\"- Sample count: {N_SAMPLES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f957f9d-26a1-4367-8464-0973fde4aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up compute device\n",
    "device, multi_gpu = setup_device()\n",
    "device_name = f\"({device.type.upper()})\" if not multi_gpu else f\"(Multi-GPU)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb5f57-ac35-4ef3-83aa-f5abe01b29d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Generating real data ({DATASET_TYPE})\")\n",
    "real_data = generate_real_data(n_samples=N_SAMPLES, dataset_type=DATASET_TYPE, device=device)\n",
    "print(f\"Generated {len(real_data):,} samples on {device}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "real_np = real_data.cpu().numpy()\n",
    "plt.scatter(real_np[:, 0], real_np[:, 1], alpha=0.7, c='blue', s=10)\n",
    "plt.title(f'Target Distribution: {DATASET_TYPE.capitalize()}', fontsize=16, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2bb670-0f43-492b-a3e4-b5bd2ac72615",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(noise_dim=NOISE_DIM)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# Move to device and get parameter counts\n",
    "generator.to(device)\n",
    "discriminator.to(device)\n",
    "\n",
    "gen_params = sum(p.numel() for p in generator.parameters())\n",
    "disc_params = sum(p.numel() for p in discriminator.parameters())\n",
    "total_params = gen_params + disc_params\n",
    "\n",
    "print(f\"Generator parameters: {gen_params:,}\")\n",
    "print(f\"Discriminator parameters: {disc_params:,}\")\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be7000b-010a-4703-946e-3046cc5c4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_samples = generate_samples(generator, NOISE_DIM, 1000, device)\n",
    "plot_data_comparison(\n",
    "    real_data, initial_samples,\n",
    "    title_prefix=f\"BEFORE Training: Random Generator vs Target {device_name}\",\n",
    "    fake_label=\"Generated (Untrained)\",\n",
    "    fake_color='red'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1ece3-1d75-461a-8269-9b93c5676daa",
   "metadata": {},
   "source": [
    "**Analysis of BEFORE state**:\n",
    "- Untrained generator produces random, unstructured data\n",
    "- No resemblance to target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d78f42-f335-49eb-b52c-fb249c8ee9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN Training\n",
    "g_losses, d_losses = train_gan(\n",
    "    generator, discriminator, real_data, device, multi_gpu,\n",
    "    noise_dim=NOISE_DIM, epochs=EPOCHS, batch_size=1024, lr_g=0.0002, lr_d=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b160199-fb31-4c19-8743-2f8352ec8ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generated Data After Training\n",
    "final_samples = generate_samples(generator, NOISE_DIM, 1000, device)\n",
    "plot_data_comparison(\n",
    "    real_data, final_samples,\n",
    "    title_prefix=f\"AFTER Training: Learned Generator Results {device_name}\",\n",
    "    fake_label=\"Generated (Trained)\",\n",
    "    fake_color='orange'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36bbd9-2af3-46d6-889c-61a88272b5fd",
   "metadata": {},
   "source": [
    "**Analysis of AFTER state**:\n",
    "- Generated data should now closely matches target distribution!\n",
    "- Clear improvement from random scatter to structured pattern\n",
    "- GAN successfully learned the underlying data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c47443-e3cd-4252-8e7c-25ad219d1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing training dynamics...\n",
    "plot_training_losses(g_losses, d_losses, device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515dc87f-37ea-417f-9413-76c62b3b93b1",
   "metadata": {},
   "source": [
    "**Key Observations**:\n",
    "- Generator loss should generally decrease over time\n",
    "- Discriminator loss should stabilize (not go to zero)\n",
    "- Loss ratio near 1.0 indicates good balance\n",
    "- Some oscillation is normal in adversarial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed8e343-9041-42e9-8edd-91a645756157",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nResults Summary:\")\n",
    "print(f\"   Dataset: {DATASET_TYPE}\")\n",
    "print(f\"   Training epochs: {EPOCHS}\")\n",
    "print(f\"   Final Generator loss: {g_losses[-1]:.4f}\")\n",
    "print(f\"   Final Discriminator loss: {d_losses[-1]:.4f}\")\n",
    "print(f\"   Device used: {device} {device_name}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    memory_used = torch.cuda.max_memory_allocated() / 1e9\n",
    "    print(f\"   Peak GPU memory: {memory_used:.2f} GB\")\n",
    "\n",
    "# Cleanup\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8cb1b3-c309-4ef0-9c93-0bca1a612e20",
   "metadata": {},
   "source": [
    "**Key Takeaways**:\n",
    "- GANs transform random noise into structured, realistic data\n",
    "- Training involves competition between generator and discriminator\n",
    "- Proper balance is crucial - neither network should dominate\n",
    "- Visual comparison shows dramatic improvement from training\n",
    "\n",
    "**Try These Experiments**:\n",
    "- Change DATASET_TYPE to see different patterns\n",
    "- Adjust EPOCHS for longer/shorter training\n",
    "- Modify NOISE_DIM to see effect on diversity\n",
    "- Try different learning rates in train_gan()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c89acb-8874-4ea5-9fd2-cb95282b5afd",
   "metadata": {},
   "source": [
    "# Part 3: HuggingFace Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49c08a9-0faa-4f72-9890-a0099c08d0c4",
   "metadata": {},
   "source": [
    "**Instructions**:\n",
    "1. Create Your HuggingFace Account at https://huggingface.co/, if you don't already have one.\n",
    "2. Go to **\"Settings\"** and then **\"Access Tokens\"**.\n",
    "3. Generate a **\"New token\"** with Read permissions\n",
    "4. Copy and save your token immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0021cfd-40b2-490c-ae94-ef66f7a22bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import login\n",
    "\n",
    "# TODO: Get your own HuggingFace Token and add it here.\n",
    "\n",
    "def setup_huggingface_auth():\n",
    "    \"\"\" Set up Hugging Face authentication \"\"\"\n",
    "    \n",
    "    hf_token = \"hf_YOUR_TOKEN_HERE\"\n",
    "    \n",
    "    try:\n",
    "        login(token=hf_token, add_to_git_credential=False)\n",
    "        print(\"Successfully authenticated with Hugging Face\")\n",
    "        return hf_token\n",
    "    except Exception as e:\n",
    "        print(f\"Authentication failed: {e}\")\n",
    "        print(\"Please check your token and try again\")\n",
    "        return None\n",
    "\n",
    "# Authenticate\n",
    "HF_TOKEN = setup_huggingface_auth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04859a9-2b09-4366-b168-fb08635d5ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "from PIL import Image\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bc2a2-8a15-471a-8a35-1c59c13398bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a simple text generation pipeline\n",
    "\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"microsoft/DialoGPT-small\",  # Small model for demo\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Test text generation\n",
    "prompt = \"The future of AI in education is\"\n",
    "result = text_generator(\n",
    "    prompt, \n",
    "    max_length=50, \n",
    "    num_return_sequences=1,\n",
    "    truncation=True,          # silence truncation warning\n",
    "    pad_token_id=50256        # ensure consistent padding\n",
    "    )\n",
    "\n",
    "print(f\"\\nText Generation:\")\n",
    "print(f\"Prompt: '{prompt}'\")\n",
    "print(f\"Generated: '{result[0]['generated_text']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a1fc9b-f408-4eb7-baef-311936adf7b7",
   "metadata": {},
   "source": [
    "---\n",
    "- HuggingFace provides pre-trained models\n",
    "- 'pipeline' abstracts away complexity\n",
    "- No training required - just use!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7098c9-aa68-4e6c-814a-763bcffb3512",
   "metadata": {},
   "source": [
    "**HuggingFace Architecture**:\n",
    "- The Hub (huggingface.co/models):\n",
    "- 400,000+ pre-trained models\n",
    "- Models for every AI task imaginable\n",
    "- Community contributions and official models\n",
    "\n",
    "**Key Libraries**:\n",
    "- transformers: NLP models (BERT, GPT, etc.)\n",
    "- diffusers: Image generation models\n",
    "- datasets: Pre-processed datasets\n",
    "- accelerate: Multi-GPU training\n",
    "\n",
    "**Pipeline Pattern**:\n",
    "- High-level API for common tasks\n",
    "- Handles tokenization, model loading, post-processing\n",
    "- Perfect for rapid prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cd6460-0ef3-46f3-9aaa-57c3d0d96030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipelines\n",
    "import random\n",
    "\n",
    "available_tasks = list(pipelines.SUPPORTED_TASKS.keys())\n",
    "random_tasks = random.sample(available_tasks, 10)\n",
    "\n",
    "print(f\"\\nAvailable Pipeline Tasks ({len(available_tasks)} total):\")\n",
    "for task in random_tasks:\n",
    "    print(f\"   • {task}\")\n",
    "print(\"   • ... and many more!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aba3211-ccc5-49e0-83ca-c24e135eee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stable Diffusion Pipeline\n",
    "from diffusers import StableDiffusionPipeline\n",
    "\n",
    "# Load the Stable Diffusion pipeline\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "# For CPU (slower but works everywhere)\n",
    "if device == \"cpu\":\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float32\n",
    "    )\n",
    "    pipe = pipe.to(device)\n",
    "else:\n",
    "    # For GPU (much faster)\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    pipe = pipe.to(device)\n",
    "\n",
    "print(\"Stable Diffusion loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2daf0-c78c-46fb-8d73-3a0194bbf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_display(prompt, num_images=2):\n",
    "    \"\"\"Generate and display images from text prompt\"\"\"\n",
    "    \n",
    "    # Autocast for GPU acceleration\n",
    "    with torch.autocast(device_type=device.type):\n",
    "        images = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=20,   # Fewer steps = faster, but lower quality\n",
    "            guidance_scale=7.5,       # How closely to follow the prompt\n",
    "            num_images_per_prompt=num_images\n",
    "        ).images\n",
    "    \n",
    "    # Display results\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(12, 6))\n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for i, (img, ax) in enumerate(zip(images, axes)):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Prompt: \\\"{prompt}\\\"', fontsize=14, y=0.95)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return images\n",
    "\n",
    "# Let's generate some images!\n",
    "prompts_to_try = [\n",
    "    \"a cute robot learning to paint\",\n",
    "    \"a futuristic classroom with AI teachers\",\n",
    "    \"a cat wearing a graduation cap reading a book\"\n",
    "]\n",
    "\n",
    "for prompt in prompts_to_try:\n",
    "    images = generate_and_display(prompt, num_images=2)\n",
    "    print(f\"Generated {len(images)} images successfully!\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ee7967-4adc-4dab-a9c2-c9da7a91d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter exploration\n",
    "prompt = \"a cat wearing a graduation cap reading a book\"\n",
    "\n",
    "# Different guidance scales\n",
    "guidance_scales = [1.0, 7.5, 15.0]\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for i, scale in enumerate(guidance_scales):\n",
    "    print(f\"   Generating with guidance_scale={scale}...\")\n",
    "    \n",
    "    with torch.autocast(device_type=device.type):\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=20,\n",
    "            guidance_scale=scale,\n",
    "            num_images_per_prompt=1\n",
    "        ).images[0]\n",
    "    \n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(f'Guidance Scale: {scale}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('Effect of Guidance Scale on Image Generation')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c275436f-dbe4-409a-bfb7-19e699e13579",
   "metadata": {},
   "source": [
    "**Parameter Effects**:\n",
    "- guidance_scale=1.0: More creative, less prompt adherence\n",
    "- guidance_scale=7.5: Balanced (recommended)\n",
    "- guidance_scale=15.0: Strict prompt following, less creativity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd390c06-0ffb-44fa-a579-8cf80a4af67f",
   "metadata": {},
   "source": [
    "---\n",
    "**Navigating the HuggingFace Model Hub**:\n",
    "Go to: https://huggingface.co/models\n",
    " \n",
    "**Key Filters to Understand**:\n",
    "- Task: What the model does (text-generation, image-to-text, etc.)\n",
    "- Library: Which framework (transformers, diffusers, etc.)\n",
    "- Language: For text models\n",
    "- License: Important for commercial use\n",
    "\n",
    "**Popular Model Categories for Our Course**:\n",
    "- Text Generation:, GPT-2, GPT-J, FLAN-T5, Meta's LLaMA models\n",
    "- Image Generation: Stable Diffusion variants, DALL-E mini\n",
    "- Text-to-Image: stable-diffusion-v1-5, stable-diffusion-2-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4491df-8ee1-4051-bbe3-b47a2a56d15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo: Load a different model type\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "sentiment = classifier(\"HuggingFace makes AI development so much easier!\")\n",
    "\n",
    "print(f\"Sentiment Analysis: {sentiment[0]['label']} ({sentiment[0]['score']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b6363-38b2-45ec-94e6-8bce12350de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
