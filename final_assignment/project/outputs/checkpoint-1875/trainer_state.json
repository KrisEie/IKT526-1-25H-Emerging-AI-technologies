{
  "best_global_step": 1875,
  "best_metric": 1.4041787385940552,
  "best_model_checkpoint": "C:\\Users\\keiel\\Skole\\IKT526-1-25H-Emerging-AI-technologies\\final_assignment\\project\\outputs\\checkpoint-1875",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 1875,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.016,
      "grad_norm": 0.4543340504169464,
      "learning_rate": 0.00019904,
      "loss": 1.6841,
      "step": 10
    },
    {
      "epoch": 0.032,
      "grad_norm": 0.5396260619163513,
      "learning_rate": 0.00019797333333333334,
      "loss": 1.5274,
      "step": 20
    },
    {
      "epoch": 0.048,
      "grad_norm": 0.589374840259552,
      "learning_rate": 0.0001969066666666667,
      "loss": 1.5014,
      "step": 30
    },
    {
      "epoch": 0.064,
      "grad_norm": 0.5510169267654419,
      "learning_rate": 0.00019584,
      "loss": 1.4873,
      "step": 40
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.795640230178833,
      "learning_rate": 0.00019477333333333335,
      "loss": 1.422,
      "step": 50
    },
    {
      "epoch": 0.096,
      "grad_norm": 0.620746374130249,
      "learning_rate": 0.00019370666666666667,
      "loss": 1.4543,
      "step": 60
    },
    {
      "epoch": 0.112,
      "grad_norm": 0.5641581416130066,
      "learning_rate": 0.00019264,
      "loss": 1.4155,
      "step": 70
    },
    {
      "epoch": 0.128,
      "grad_norm": 0.6447172164916992,
      "learning_rate": 0.00019157333333333335,
      "loss": 1.4457,
      "step": 80
    },
    {
      "epoch": 0.144,
      "grad_norm": 0.5879129767417908,
      "learning_rate": 0.00019050666666666668,
      "loss": 1.4633,
      "step": 90
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.5714684724807739,
      "learning_rate": 0.00018944000000000003,
      "loss": 1.4808,
      "step": 100
    },
    {
      "epoch": 0.176,
      "grad_norm": 0.5226572155952454,
      "learning_rate": 0.00018837333333333333,
      "loss": 1.4447,
      "step": 110
    },
    {
      "epoch": 0.192,
      "grad_norm": 0.47219306230545044,
      "learning_rate": 0.00018730666666666668,
      "loss": 1.4153,
      "step": 120
    },
    {
      "epoch": 0.208,
      "grad_norm": 0.48865681886672974,
      "learning_rate": 0.00018624,
      "loss": 1.3793,
      "step": 130
    },
    {
      "epoch": 0.224,
      "grad_norm": 0.6078200936317444,
      "learning_rate": 0.00018517333333333333,
      "loss": 1.4508,
      "step": 140
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.6615299582481384,
      "learning_rate": 0.00018410666666666668,
      "loss": 1.4184,
      "step": 150
    },
    {
      "epoch": 0.256,
      "grad_norm": 0.5969527959823608,
      "learning_rate": 0.00018304,
      "loss": 1.4347,
      "step": 160
    },
    {
      "epoch": 0.272,
      "grad_norm": 0.6616458296775818,
      "learning_rate": 0.00018197333333333336,
      "loss": 1.4251,
      "step": 170
    },
    {
      "epoch": 0.288,
      "grad_norm": 0.4550626575946808,
      "learning_rate": 0.00018090666666666666,
      "loss": 1.4331,
      "step": 180
    },
    {
      "epoch": 0.304,
      "grad_norm": 0.4866446256637573,
      "learning_rate": 0.00017984,
      "loss": 1.4295,
      "step": 190
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.5852909088134766,
      "learning_rate": 0.00017877333333333334,
      "loss": 1.4483,
      "step": 200
    },
    {
      "epoch": 0.336,
      "grad_norm": 0.5085484981536865,
      "learning_rate": 0.00017770666666666666,
      "loss": 1.3738,
      "step": 210
    },
    {
      "epoch": 0.352,
      "grad_norm": 0.46658673882484436,
      "learning_rate": 0.00017664000000000002,
      "loss": 1.4192,
      "step": 220
    },
    {
      "epoch": 0.368,
      "grad_norm": 0.5923185348510742,
      "learning_rate": 0.00017557333333333334,
      "loss": 1.4509,
      "step": 230
    },
    {
      "epoch": 0.384,
      "grad_norm": 0.45699816942214966,
      "learning_rate": 0.0001745066666666667,
      "loss": 1.4285,
      "step": 240
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.5603040456771851,
      "learning_rate": 0.00017344,
      "loss": 1.4052,
      "step": 250
    },
    {
      "epoch": 0.416,
      "grad_norm": 0.6214241981506348,
      "learning_rate": 0.00017237333333333335,
      "loss": 1.4072,
      "step": 260
    },
    {
      "epoch": 0.432,
      "grad_norm": 0.510936975479126,
      "learning_rate": 0.00017130666666666667,
      "loss": 1.4348,
      "step": 270
    },
    {
      "epoch": 0.448,
      "grad_norm": 0.48830446600914,
      "learning_rate": 0.00017024,
      "loss": 1.4486,
      "step": 280
    },
    {
      "epoch": 0.464,
      "grad_norm": 0.6316732168197632,
      "learning_rate": 0.00016917333333333335,
      "loss": 1.4195,
      "step": 290
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6325472593307495,
      "learning_rate": 0.00016810666666666667,
      "loss": 1.3879,
      "step": 300
    },
    {
      "epoch": 0.496,
      "grad_norm": 0.5560464262962341,
      "learning_rate": 0.00016704000000000003,
      "loss": 1.3753,
      "step": 310
    },
    {
      "epoch": 0.512,
      "grad_norm": 0.4665954113006592,
      "learning_rate": 0.00016597333333333333,
      "loss": 1.3369,
      "step": 320
    },
    {
      "epoch": 0.528,
      "grad_norm": 0.4938748776912689,
      "learning_rate": 0.00016490666666666668,
      "loss": 1.4072,
      "step": 330
    },
    {
      "epoch": 0.544,
      "grad_norm": 0.5129051804542542,
      "learning_rate": 0.00016384,
      "loss": 1.4045,
      "step": 340
    },
    {
      "epoch": 0.56,
      "grad_norm": 0.6136147379875183,
      "learning_rate": 0.00016277333333333333,
      "loss": 1.4586,
      "step": 350
    },
    {
      "epoch": 0.576,
      "grad_norm": 0.5105193257331848,
      "learning_rate": 0.00016170666666666668,
      "loss": 1.3959,
      "step": 360
    },
    {
      "epoch": 0.592,
      "grad_norm": 0.7088888883590698,
      "learning_rate": 0.00016064,
      "loss": 1.4123,
      "step": 370
    },
    {
      "epoch": 0.608,
      "grad_norm": 0.6001439690589905,
      "learning_rate": 0.00015957333333333333,
      "loss": 1.4746,
      "step": 380
    },
    {
      "epoch": 0.624,
      "grad_norm": 0.5882436633110046,
      "learning_rate": 0.00015850666666666666,
      "loss": 1.4336,
      "step": 390
    },
    {
      "epoch": 0.64,
      "grad_norm": 0.8209248185157776,
      "learning_rate": 0.00015744,
      "loss": 1.4235,
      "step": 400
    },
    {
      "epoch": 0.656,
      "grad_norm": 0.6899423599243164,
      "learning_rate": 0.00015637333333333334,
      "loss": 1.3816,
      "step": 410
    },
    {
      "epoch": 0.672,
      "grad_norm": 0.40623924136161804,
      "learning_rate": 0.00015530666666666666,
      "loss": 1.3896,
      "step": 420
    },
    {
      "epoch": 0.688,
      "grad_norm": 0.7769606113433838,
      "learning_rate": 0.00015424000000000001,
      "loss": 1.448,
      "step": 430
    },
    {
      "epoch": 0.704,
      "grad_norm": 0.5470489859580994,
      "learning_rate": 0.00015317333333333334,
      "loss": 1.3332,
      "step": 440
    },
    {
      "epoch": 0.72,
      "grad_norm": 0.414543479681015,
      "learning_rate": 0.00015210666666666666,
      "loss": 1.383,
      "step": 450
    },
    {
      "epoch": 0.736,
      "grad_norm": 0.4307502806186676,
      "learning_rate": 0.00015104,
      "loss": 1.4219,
      "step": 460
    },
    {
      "epoch": 0.752,
      "grad_norm": 0.5151352286338806,
      "learning_rate": 0.00014997333333333334,
      "loss": 1.4297,
      "step": 470
    },
    {
      "epoch": 0.768,
      "grad_norm": 0.5183475613594055,
      "learning_rate": 0.0001489066666666667,
      "loss": 1.4544,
      "step": 480
    },
    {
      "epoch": 0.784,
      "grad_norm": 0.5304298400878906,
      "learning_rate": 0.00014784,
      "loss": 1.428,
      "step": 490
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.5061352252960205,
      "learning_rate": 0.00014677333333333335,
      "loss": 1.4104,
      "step": 500
    },
    {
      "epoch": 0.816,
      "grad_norm": 0.4484393000602722,
      "learning_rate": 0.00014570666666666667,
      "loss": 1.4434,
      "step": 510
    },
    {
      "epoch": 0.832,
      "grad_norm": 0.43475964665412903,
      "learning_rate": 0.00014464,
      "loss": 1.403,
      "step": 520
    },
    {
      "epoch": 0.848,
      "grad_norm": 0.5766461491584778,
      "learning_rate": 0.00014357333333333335,
      "loss": 1.421,
      "step": 530
    },
    {
      "epoch": 0.864,
      "grad_norm": 0.4805566072463989,
      "learning_rate": 0.00014250666666666668,
      "loss": 1.3472,
      "step": 540
    },
    {
      "epoch": 0.88,
      "grad_norm": 0.40828007459640503,
      "learning_rate": 0.00014144000000000003,
      "loss": 1.4478,
      "step": 550
    },
    {
      "epoch": 0.896,
      "grad_norm": 0.4880525469779968,
      "learning_rate": 0.00014037333333333333,
      "loss": 1.4263,
      "step": 560
    },
    {
      "epoch": 0.912,
      "grad_norm": 0.4345439374446869,
      "learning_rate": 0.00013930666666666668,
      "loss": 1.3648,
      "step": 570
    },
    {
      "epoch": 0.928,
      "grad_norm": 0.49795180559158325,
      "learning_rate": 0.00013824,
      "loss": 1.3587,
      "step": 580
    },
    {
      "epoch": 0.944,
      "grad_norm": 0.4234093129634857,
      "learning_rate": 0.00013717333333333333,
      "loss": 1.4688,
      "step": 590
    },
    {
      "epoch": 0.96,
      "grad_norm": 0.6284177899360657,
      "learning_rate": 0.00013610666666666668,
      "loss": 1.4122,
      "step": 600
    },
    {
      "epoch": 0.976,
      "grad_norm": 0.5100958943367004,
      "learning_rate": 0.00013504,
      "loss": 1.4489,
      "step": 610
    },
    {
      "epoch": 0.992,
      "grad_norm": 0.4826999604701996,
      "learning_rate": 0.00013397333333333336,
      "loss": 1.3807,
      "step": 620
    },
    {
      "epoch": 1.0,
      "eval_loss": 1.4157829284667969,
      "eval_runtime": 25.5832,
      "eval_samples_per_second": 78.176,
      "eval_steps_per_second": 9.772,
      "step": 625
    },
    {
      "epoch": 1.008,
      "grad_norm": 0.5965802073478699,
      "learning_rate": 0.00013290666666666666,
      "loss": 1.39,
      "step": 630
    },
    {
      "epoch": 1.024,
      "grad_norm": 0.40258362889289856,
      "learning_rate": 0.00013184,
      "loss": 1.3749,
      "step": 640
    },
    {
      "epoch": 1.04,
      "grad_norm": 0.5042962431907654,
      "learning_rate": 0.00013077333333333334,
      "loss": 1.4002,
      "step": 650
    },
    {
      "epoch": 1.056,
      "grad_norm": 0.66756272315979,
      "learning_rate": 0.00012970666666666666,
      "loss": 1.395,
      "step": 660
    },
    {
      "epoch": 1.072,
      "grad_norm": 0.5679048895835876,
      "learning_rate": 0.00012864000000000002,
      "loss": 1.3528,
      "step": 670
    },
    {
      "epoch": 1.088,
      "grad_norm": 0.6291671395301819,
      "learning_rate": 0.00012757333333333334,
      "loss": 1.4372,
      "step": 680
    },
    {
      "epoch": 1.104,
      "grad_norm": 0.6423979997634888,
      "learning_rate": 0.00012650666666666667,
      "loss": 1.3843,
      "step": 690
    },
    {
      "epoch": 1.12,
      "grad_norm": 0.5587180256843567,
      "learning_rate": 0.00012544,
      "loss": 1.4049,
      "step": 700
    },
    {
      "epoch": 1.1360000000000001,
      "grad_norm": 0.5728039145469666,
      "learning_rate": 0.00012437333333333334,
      "loss": 1.4224,
      "step": 710
    },
    {
      "epoch": 1.152,
      "grad_norm": 0.5361737608909607,
      "learning_rate": 0.00012330666666666667,
      "loss": 1.3699,
      "step": 720
    },
    {
      "epoch": 1.168,
      "grad_norm": 0.5713326334953308,
      "learning_rate": 0.00012224,
      "loss": 1.3707,
      "step": 730
    },
    {
      "epoch": 1.184,
      "grad_norm": 0.5039006471633911,
      "learning_rate": 0.00012117333333333333,
      "loss": 1.4327,
      "step": 740
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5539166927337646,
      "learning_rate": 0.00012010666666666667,
      "loss": 1.4058,
      "step": 750
    },
    {
      "epoch": 1.216,
      "grad_norm": 0.5604466199874878,
      "learning_rate": 0.00011904,
      "loss": 1.3534,
      "step": 760
    },
    {
      "epoch": 1.232,
      "grad_norm": 0.4645906090736389,
      "learning_rate": 0.00011797333333333334,
      "loss": 1.4102,
      "step": 770
    },
    {
      "epoch": 1.248,
      "grad_norm": 0.665775716304779,
      "learning_rate": 0.00011690666666666668,
      "loss": 1.4415,
      "step": 780
    },
    {
      "epoch": 1.264,
      "grad_norm": 0.6172886490821838,
      "learning_rate": 0.00011584000000000002,
      "loss": 1.3438,
      "step": 790
    },
    {
      "epoch": 1.28,
      "grad_norm": 0.5820100903511047,
      "learning_rate": 0.00011477333333333333,
      "loss": 1.3683,
      "step": 800
    },
    {
      "epoch": 1.296,
      "grad_norm": 0.7032941579818726,
      "learning_rate": 0.00011370666666666667,
      "loss": 1.4329,
      "step": 810
    },
    {
      "epoch": 1.312,
      "grad_norm": 0.479290634393692,
      "learning_rate": 0.00011264,
      "loss": 1.3775,
      "step": 820
    },
    {
      "epoch": 1.328,
      "grad_norm": 0.564019501209259,
      "learning_rate": 0.00011157333333333333,
      "loss": 1.4001,
      "step": 830
    },
    {
      "epoch": 1.3439999999999999,
      "grad_norm": 0.5345137715339661,
      "learning_rate": 0.00011050666666666667,
      "loss": 1.4314,
      "step": 840
    },
    {
      "epoch": 1.3599999999999999,
      "grad_norm": 0.7152522206306458,
      "learning_rate": 0.00010944000000000001,
      "loss": 1.3804,
      "step": 850
    },
    {
      "epoch": 1.376,
      "grad_norm": 0.6374866366386414,
      "learning_rate": 0.00010837333333333335,
      "loss": 1.3966,
      "step": 860
    },
    {
      "epoch": 1.392,
      "grad_norm": 0.5779819488525391,
      "learning_rate": 0.00010730666666666666,
      "loss": 1.3327,
      "step": 870
    },
    {
      "epoch": 1.408,
      "grad_norm": 0.7095060348510742,
      "learning_rate": 0.00010624000000000001,
      "loss": 1.3845,
      "step": 880
    },
    {
      "epoch": 1.424,
      "grad_norm": 0.5294903516769409,
      "learning_rate": 0.00010517333333333335,
      "loss": 1.3432,
      "step": 890
    },
    {
      "epoch": 1.44,
      "grad_norm": 0.6984144449234009,
      "learning_rate": 0.00010410666666666666,
      "loss": 1.3464,
      "step": 900
    },
    {
      "epoch": 1.456,
      "grad_norm": 0.5420804619789124,
      "learning_rate": 0.00010304,
      "loss": 1.3748,
      "step": 910
    },
    {
      "epoch": 1.472,
      "grad_norm": 0.4813152849674225,
      "learning_rate": 0.00010197333333333334,
      "loss": 1.4383,
      "step": 920
    },
    {
      "epoch": 1.488,
      "grad_norm": 0.6870990991592407,
      "learning_rate": 0.00010090666666666665,
      "loss": 1.3644,
      "step": 930
    },
    {
      "epoch": 1.504,
      "grad_norm": 0.5549961924552917,
      "learning_rate": 9.984e-05,
      "loss": 1.3791,
      "step": 940
    },
    {
      "epoch": 1.52,
      "grad_norm": 0.5193089842796326,
      "learning_rate": 9.877333333333335e-05,
      "loss": 1.3424,
      "step": 950
    },
    {
      "epoch": 1.536,
      "grad_norm": 0.556171178817749,
      "learning_rate": 9.770666666666667e-05,
      "loss": 1.3297,
      "step": 960
    },
    {
      "epoch": 1.552,
      "grad_norm": 0.7832832336425781,
      "learning_rate": 9.664000000000001e-05,
      "loss": 1.4078,
      "step": 970
    },
    {
      "epoch": 1.568,
      "grad_norm": 0.6002493500709534,
      "learning_rate": 9.557333333333334e-05,
      "loss": 1.3755,
      "step": 980
    },
    {
      "epoch": 1.584,
      "grad_norm": 0.5408290028572083,
      "learning_rate": 9.450666666666667e-05,
      "loss": 1.3676,
      "step": 990
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.7142324447631836,
      "learning_rate": 9.344e-05,
      "loss": 1.3405,
      "step": 1000
    },
    {
      "epoch": 1.616,
      "grad_norm": 0.6262736916542053,
      "learning_rate": 9.237333333333334e-05,
      "loss": 1.3854,
      "step": 1010
    },
    {
      "epoch": 1.6320000000000001,
      "grad_norm": 0.5178310871124268,
      "learning_rate": 9.130666666666668e-05,
      "loss": 1.4598,
      "step": 1020
    },
    {
      "epoch": 1.6480000000000001,
      "grad_norm": 0.6388627290725708,
      "learning_rate": 9.024e-05,
      "loss": 1.3958,
      "step": 1030
    },
    {
      "epoch": 1.6640000000000001,
      "grad_norm": 0.5642024278640747,
      "learning_rate": 8.917333333333334e-05,
      "loss": 1.3711,
      "step": 1040
    },
    {
      "epoch": 1.6800000000000002,
      "grad_norm": 0.6717261672019958,
      "learning_rate": 8.810666666666667e-05,
      "loss": 1.3891,
      "step": 1050
    },
    {
      "epoch": 1.696,
      "grad_norm": 0.6217706799507141,
      "learning_rate": 8.704e-05,
      "loss": 1.4168,
      "step": 1060
    },
    {
      "epoch": 1.712,
      "grad_norm": 0.672306478023529,
      "learning_rate": 8.597333333333333e-05,
      "loss": 1.3627,
      "step": 1070
    },
    {
      "epoch": 1.728,
      "grad_norm": 0.47904306650161743,
      "learning_rate": 8.490666666666667e-05,
      "loss": 1.3545,
      "step": 1080
    },
    {
      "epoch": 1.744,
      "grad_norm": 0.5152757167816162,
      "learning_rate": 8.384000000000001e-05,
      "loss": 1.4006,
      "step": 1090
    },
    {
      "epoch": 1.76,
      "grad_norm": 0.4903901517391205,
      "learning_rate": 8.277333333333334e-05,
      "loss": 1.3166,
      "step": 1100
    },
    {
      "epoch": 1.776,
      "grad_norm": 0.5932730436325073,
      "learning_rate": 8.170666666666667e-05,
      "loss": 1.3375,
      "step": 1110
    },
    {
      "epoch": 1.792,
      "grad_norm": 0.5789169073104858,
      "learning_rate": 8.064e-05,
      "loss": 1.4206,
      "step": 1120
    },
    {
      "epoch": 1.808,
      "grad_norm": 0.5242623090744019,
      "learning_rate": 7.957333333333334e-05,
      "loss": 1.3911,
      "step": 1130
    },
    {
      "epoch": 1.8239999999999998,
      "grad_norm": 0.5307187438011169,
      "learning_rate": 7.850666666666668e-05,
      "loss": 1.3899,
      "step": 1140
    },
    {
      "epoch": 1.8399999999999999,
      "grad_norm": 0.857164740562439,
      "learning_rate": 7.744e-05,
      "loss": 1.3859,
      "step": 1150
    },
    {
      "epoch": 1.8559999999999999,
      "grad_norm": 0.4847586750984192,
      "learning_rate": 7.637333333333334e-05,
      "loss": 1.3457,
      "step": 1160
    },
    {
      "epoch": 1.8719999999999999,
      "grad_norm": 0.5184285044670105,
      "learning_rate": 7.530666666666667e-05,
      "loss": 1.3813,
      "step": 1170
    },
    {
      "epoch": 1.888,
      "grad_norm": 0.48283132910728455,
      "learning_rate": 7.424e-05,
      "loss": 1.3697,
      "step": 1180
    },
    {
      "epoch": 1.904,
      "grad_norm": 0.5738301277160645,
      "learning_rate": 7.317333333333333e-05,
      "loss": 1.3308,
      "step": 1190
    },
    {
      "epoch": 1.92,
      "grad_norm": 0.642185389995575,
      "learning_rate": 7.210666666666667e-05,
      "loss": 1.3741,
      "step": 1200
    },
    {
      "epoch": 1.936,
      "grad_norm": 0.5386213064193726,
      "learning_rate": 7.104000000000001e-05,
      "loss": 1.3487,
      "step": 1210
    },
    {
      "epoch": 1.952,
      "grad_norm": 0.6437383890151978,
      "learning_rate": 6.997333333333334e-05,
      "loss": 1.345,
      "step": 1220
    },
    {
      "epoch": 1.968,
      "grad_norm": 0.5625141859054565,
      "learning_rate": 6.890666666666668e-05,
      "loss": 1.4019,
      "step": 1230
    },
    {
      "epoch": 1.984,
      "grad_norm": 0.6975976228713989,
      "learning_rate": 6.784e-05,
      "loss": 1.3497,
      "step": 1240
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6382583379745483,
      "learning_rate": 6.677333333333333e-05,
      "loss": 1.3139,
      "step": 1250
    },
    {
      "epoch": 2.0,
      "eval_loss": 1.4060957431793213,
      "eval_runtime": 25.7467,
      "eval_samples_per_second": 77.68,
      "eval_steps_per_second": 9.71,
      "step": 1250
    },
    {
      "epoch": 2.016,
      "grad_norm": 0.5073789954185486,
      "learning_rate": 6.570666666666667e-05,
      "loss": 1.4,
      "step": 1260
    },
    {
      "epoch": 2.032,
      "grad_norm": 0.6756240129470825,
      "learning_rate": 6.464e-05,
      "loss": 1.3758,
      "step": 1270
    },
    {
      "epoch": 2.048,
      "grad_norm": 0.7567418813705444,
      "learning_rate": 6.357333333333334e-05,
      "loss": 1.3338,
      "step": 1280
    },
    {
      "epoch": 2.064,
      "grad_norm": 0.6644542217254639,
      "learning_rate": 6.250666666666667e-05,
      "loss": 1.3133,
      "step": 1290
    },
    {
      "epoch": 2.08,
      "grad_norm": 0.8437009453773499,
      "learning_rate": 6.144e-05,
      "loss": 1.3161,
      "step": 1300
    },
    {
      "epoch": 2.096,
      "grad_norm": 0.6885213851928711,
      "learning_rate": 6.037333333333334e-05,
      "loss": 1.2951,
      "step": 1310
    },
    {
      "epoch": 2.112,
      "grad_norm": 0.6883330345153809,
      "learning_rate": 5.9306666666666666e-05,
      "loss": 1.3214,
      "step": 1320
    },
    {
      "epoch": 2.128,
      "grad_norm": 0.9070621132850647,
      "learning_rate": 5.8240000000000005e-05,
      "loss": 1.3876,
      "step": 1330
    },
    {
      "epoch": 2.144,
      "grad_norm": 0.572012186050415,
      "learning_rate": 5.717333333333334e-05,
      "loss": 1.3669,
      "step": 1340
    },
    {
      "epoch": 2.16,
      "grad_norm": 0.842300295829773,
      "learning_rate": 5.6106666666666676e-05,
      "loss": 1.4251,
      "step": 1350
    },
    {
      "epoch": 2.176,
      "grad_norm": 0.6296135187149048,
      "learning_rate": 5.504e-05,
      "loss": 1.3571,
      "step": 1360
    },
    {
      "epoch": 2.192,
      "grad_norm": 0.6411559581756592,
      "learning_rate": 5.3973333333333334e-05,
      "loss": 1.3536,
      "step": 1370
    },
    {
      "epoch": 2.208,
      "grad_norm": 0.7211662530899048,
      "learning_rate": 5.290666666666667e-05,
      "loss": 1.3671,
      "step": 1380
    },
    {
      "epoch": 2.224,
      "grad_norm": 0.5056520104408264,
      "learning_rate": 5.184e-05,
      "loss": 1.3017,
      "step": 1390
    },
    {
      "epoch": 2.24,
      "grad_norm": 0.6150930523872375,
      "learning_rate": 5.077333333333334e-05,
      "loss": 1.335,
      "step": 1400
    },
    {
      "epoch": 2.2560000000000002,
      "grad_norm": 0.6196092367172241,
      "learning_rate": 4.970666666666667e-05,
      "loss": 1.3399,
      "step": 1410
    },
    {
      "epoch": 2.2720000000000002,
      "grad_norm": 0.6639001369476318,
      "learning_rate": 4.864e-05,
      "loss": 1.3369,
      "step": 1420
    },
    {
      "epoch": 2.288,
      "grad_norm": 0.547888994216919,
      "learning_rate": 4.7573333333333334e-05,
      "loss": 1.3499,
      "step": 1430
    },
    {
      "epoch": 2.304,
      "grad_norm": 0.5885558128356934,
      "learning_rate": 4.650666666666667e-05,
      "loss": 1.3779,
      "step": 1440
    },
    {
      "epoch": 2.32,
      "grad_norm": 0.4679250717163086,
      "learning_rate": 4.5440000000000005e-05,
      "loss": 1.3398,
      "step": 1450
    },
    {
      "epoch": 2.336,
      "grad_norm": 0.8283233642578125,
      "learning_rate": 4.437333333333333e-05,
      "loss": 1.4062,
      "step": 1460
    },
    {
      "epoch": 2.352,
      "grad_norm": 0.8831101059913635,
      "learning_rate": 4.330666666666667e-05,
      "loss": 1.4005,
      "step": 1470
    },
    {
      "epoch": 2.368,
      "grad_norm": 0.494316428899765,
      "learning_rate": 4.224e-05,
      "loss": 1.3918,
      "step": 1480
    },
    {
      "epoch": 2.384,
      "grad_norm": 0.6269080638885498,
      "learning_rate": 4.1173333333333334e-05,
      "loss": 1.3386,
      "step": 1490
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7770190834999084,
      "learning_rate": 4.0106666666666673e-05,
      "loss": 1.2961,
      "step": 1500
    },
    {
      "epoch": 2.416,
      "grad_norm": 0.7400568723678589,
      "learning_rate": 3.9040000000000006e-05,
      "loss": 1.3677,
      "step": 1510
    },
    {
      "epoch": 2.432,
      "grad_norm": 0.5462753772735596,
      "learning_rate": 3.797333333333333e-05,
      "loss": 1.3745,
      "step": 1520
    },
    {
      "epoch": 2.448,
      "grad_norm": 0.6001191735267639,
      "learning_rate": 3.690666666666667e-05,
      "loss": 1.3102,
      "step": 1530
    },
    {
      "epoch": 2.464,
      "grad_norm": 0.567852258682251,
      "learning_rate": 3.584e-05,
      "loss": 1.3287,
      "step": 1540
    },
    {
      "epoch": 2.48,
      "grad_norm": 0.5380880832672119,
      "learning_rate": 3.4773333333333335e-05,
      "loss": 1.3473,
      "step": 1550
    },
    {
      "epoch": 2.496,
      "grad_norm": 0.6031156182289124,
      "learning_rate": 3.370666666666667e-05,
      "loss": 1.3455,
      "step": 1560
    },
    {
      "epoch": 2.512,
      "grad_norm": 0.6919964551925659,
      "learning_rate": 3.2640000000000006e-05,
      "loss": 1.3945,
      "step": 1570
    },
    {
      "epoch": 2.528,
      "grad_norm": 0.7561082243919373,
      "learning_rate": 3.157333333333333e-05,
      "loss": 1.3285,
      "step": 1580
    },
    {
      "epoch": 2.544,
      "grad_norm": 0.6451535820960999,
      "learning_rate": 3.0506666666666667e-05,
      "loss": 1.3317,
      "step": 1590
    },
    {
      "epoch": 2.56,
      "grad_norm": 0.5849937796592712,
      "learning_rate": 2.944e-05,
      "loss": 1.3378,
      "step": 1600
    },
    {
      "epoch": 2.576,
      "grad_norm": 0.5330579876899719,
      "learning_rate": 2.8373333333333335e-05,
      "loss": 1.3981,
      "step": 1610
    },
    {
      "epoch": 2.592,
      "grad_norm": 0.5921729803085327,
      "learning_rate": 2.730666666666667e-05,
      "loss": 1.3549,
      "step": 1620
    },
    {
      "epoch": 2.608,
      "grad_norm": 0.7581198811531067,
      "learning_rate": 2.6240000000000003e-05,
      "loss": 1.366,
      "step": 1630
    },
    {
      "epoch": 2.624,
      "grad_norm": 0.5649632811546326,
      "learning_rate": 2.5173333333333332e-05,
      "loss": 1.3591,
      "step": 1640
    },
    {
      "epoch": 2.64,
      "grad_norm": 0.7173444628715515,
      "learning_rate": 2.4106666666666667e-05,
      "loss": 1.3681,
      "step": 1650
    },
    {
      "epoch": 2.656,
      "grad_norm": 0.5884236097335815,
      "learning_rate": 2.304e-05,
      "loss": 1.2772,
      "step": 1660
    },
    {
      "epoch": 2.672,
      "grad_norm": 0.6328152418136597,
      "learning_rate": 2.1973333333333335e-05,
      "loss": 1.3533,
      "step": 1670
    },
    {
      "epoch": 2.6879999999999997,
      "grad_norm": 0.5252499580383301,
      "learning_rate": 2.0906666666666668e-05,
      "loss": 1.3659,
      "step": 1680
    },
    {
      "epoch": 2.7039999999999997,
      "grad_norm": 0.5801029801368713,
      "learning_rate": 1.984e-05,
      "loss": 1.3805,
      "step": 1690
    },
    {
      "epoch": 2.7199999999999998,
      "grad_norm": 0.7335616946220398,
      "learning_rate": 1.8773333333333335e-05,
      "loss": 1.3361,
      "step": 1700
    },
    {
      "epoch": 2.7359999999999998,
      "grad_norm": 0.4902316927909851,
      "learning_rate": 1.7706666666666668e-05,
      "loss": 1.401,
      "step": 1710
    },
    {
      "epoch": 2.752,
      "grad_norm": 0.6526703834533691,
      "learning_rate": 1.664e-05,
      "loss": 1.352,
      "step": 1720
    },
    {
      "epoch": 2.768,
      "grad_norm": 0.8524516224861145,
      "learning_rate": 1.5573333333333336e-05,
      "loss": 1.4031,
      "step": 1730
    },
    {
      "epoch": 2.784,
      "grad_norm": 0.6324512362480164,
      "learning_rate": 1.4506666666666668e-05,
      "loss": 1.3816,
      "step": 1740
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.6153696775436401,
      "learning_rate": 1.344e-05,
      "loss": 1.3238,
      "step": 1750
    },
    {
      "epoch": 2.816,
      "grad_norm": 0.5994318127632141,
      "learning_rate": 1.2373333333333334e-05,
      "loss": 1.3957,
      "step": 1760
    },
    {
      "epoch": 2.832,
      "grad_norm": 0.5551560521125793,
      "learning_rate": 1.1306666666666666e-05,
      "loss": 1.422,
      "step": 1770
    },
    {
      "epoch": 2.848,
      "grad_norm": 0.596623420715332,
      "learning_rate": 1.024e-05,
      "loss": 1.408,
      "step": 1780
    },
    {
      "epoch": 2.864,
      "grad_norm": 0.660394549369812,
      "learning_rate": 9.173333333333334e-06,
      "loss": 1.3518,
      "step": 1790
    },
    {
      "epoch": 2.88,
      "grad_norm": 0.5619659423828125,
      "learning_rate": 8.106666666666666e-06,
      "loss": 1.3252,
      "step": 1800
    },
    {
      "epoch": 2.896,
      "grad_norm": 0.6419781446456909,
      "learning_rate": 7.04e-06,
      "loss": 1.3756,
      "step": 1810
    },
    {
      "epoch": 2.912,
      "grad_norm": 0.6294218301773071,
      "learning_rate": 5.9733333333333335e-06,
      "loss": 1.3139,
      "step": 1820
    },
    {
      "epoch": 2.928,
      "grad_norm": 0.6835703253746033,
      "learning_rate": 4.906666666666667e-06,
      "loss": 1.3666,
      "step": 1830
    },
    {
      "epoch": 2.944,
      "grad_norm": 0.5422751903533936,
      "learning_rate": 3.84e-06,
      "loss": 1.3202,
      "step": 1840
    },
    {
      "epoch": 2.96,
      "grad_norm": 0.5780383944511414,
      "learning_rate": 2.773333333333333e-06,
      "loss": 1.3636,
      "step": 1850
    },
    {
      "epoch": 2.976,
      "grad_norm": 0.48322176933288574,
      "learning_rate": 1.706666666666667e-06,
      "loss": 1.3893,
      "step": 1860
    },
    {
      "epoch": 2.992,
      "grad_norm": 0.5831312537193298,
      "learning_rate": 6.4e-07,
      "loss": 1.3433,
      "step": 1870
    },
    {
      "epoch": 3.0,
      "eval_loss": 1.4041787385940552,
      "eval_runtime": 30.1929,
      "eval_samples_per_second": 66.241,
      "eval_steps_per_second": 8.28,
      "step": 1875
    }
  ],
  "logging_steps": 10,
  "max_steps": 1875,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.984218042368e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
